{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "e8225db4-e61d-4640-8b1f-8bfce3331cea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  v7.0-187-g0004c74 Python-3.7.2 torch-1.13.1+cpu CPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete  (32 CPUs, 64.0 GB RAM, 7814.2/8191.9 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 46, in <module>\n",
            "    ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
            "  File \"c:\\Miniconda\\envs\\yolov5_v2\\lib\\ntpath.py\", line 562, in relpath\n",
            "    path_drive, start_drive))\n",
            "ValueError: path is on mount '\\\\\\\\LVAUKSLVEDGW001\\\\Pricing', start on mount 'w:'\n"
          ]
        }
      ],
      "source": [
        "# Train YOLOv5s on standard train valid image 2000 images set for 200 epochs\n",
        "# 1cpu, 16 batch, 4000 images, 1 epoch - 64 mins\n",
        "!python train.py --img 640 --batch 32 --epochs 1 --data standard_train.yaml --weights yolov5s.pt --cache --single-cls --freeze 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tuning HPs\n",
        "# Done purely on the standard train dataset and assume given the similarity o fthe use case that findings are same for other models\n",
        "# 1 get evolved HPs - see if improves\n",
        "# 2 test freeze/non freeze\n",
        "\n",
        "# 1 TUNING standard: YOLOv5s on standrad train 2000 images set for 200 (change if best in above lower) epochs\n",
        "!python train.py --img 640 --batch 32 --epochs 200 --data standard_train.yaml --weights yolov5s.pt --cache --single-cls --freeze [10] --evolve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2 Training standard: YOLOv5s on standrad train 2000 images set for 200 (change if best in above lower) epochs\n",
        "!python train.py --img 640 --batch 32 --epochs 200 --data standard_train.yaml --weights yolov5s.pt --cache --single-cls --freeze [10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/standard_train.yaml\n",
            "{0: 'Spot'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp16/weights/best.pt'], source=data/images, data=data/standard_train.yaml, imgsz=[640, 640], conf_thres=0.7, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5  v7.0-187-g0004c74 Python-3.7.2 torch-1.13.1+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/4 C:\\Users\\adm.alexander.farquh\\DSMP\\yolov5\\data\\images\\bus.jpg: 640x480 (no detections), 119.0ms\n",
            "image 2/4 C:\\Users\\adm.alexander.farquh\\DSMP\\yolov5\\data\\images\\image_0000.jpg: 640x640 2 Spots, 147.0ms\n",
            "image 3/4 C:\\Users\\adm.alexander.farquh\\DSMP\\yolov5\\data\\images\\image_0001_jpg.rf.b7d1fd6d6682accd58206147be2d220a.jpg: 640x640 1 Spot, 137.0ms\n",
            "image 4/4 C:\\Users\\adm.alexander.farquh\\DSMP\\yolov5\\data\\images\\zidane.jpg: 384x640 (no detections), 88.0ms\n",
            "Speed: 0.8ms pre-process, 122.8ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns\\detect\\exp27\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# See if its worked - predict on an image\n",
        "!python detect.py --weights runs/train/exp16/weights/best.pt --img 640 --conf 0.7 --source data/images --data data/standard_train.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X58w8JLpMnjH",
        "outputId": "3e234e05-ee8b-4ad1-b1a4-f6a55d5e4f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'Spot'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=data/standard_train.yaml, weights=['runs/train/exp16/weights/best.pt'], batch_size=32, imgsz=620, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs\\val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5  v7.0-187-g0004c74 Python-3.7.2 torch-1.13.1+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "WARNING  --img-size 620 must be multiple of max stride 32, updating to 640\n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\adm.alexander.farquh\\DSMP\\datasets\\standard_train\\labels\\temp.cache... 251 images, 0 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\adm.alexander.farquh\\DSMP\\datasets\\standard_train\\labels\\temp.cache... 251 images, 0 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:00<?, ?it/s]\n",
            "\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/8 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  12%|█▎        | 1/8 [00:06<00:43,  6.16s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 2/8 [00:12<00:36,  6.04s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  38%|███▊      | 3/8 [00:18<00:30,  6.02s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 4/8 [00:24<00:24,  6.06s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  62%|██████▎   | 5/8 [00:29<00:17,  5.90s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 6/8 [00:35<00:11,  5.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  88%|████████▊ | 7/8 [00:41<00:05,  5.86s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 8/8 [00:46<00:00,  5.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 8/8 [00:46<00:00,  5.80s/it]\n",
            "                   all        251      13635      0.759      0.912      0.923      0.554\n",
            "Speed: 1.1ms pre-process, 129.5ms inference, 41.1ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns\\val\\exp3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Validate YOLOv5s #--half\n",
        "!python val.py --weights runs/train/exp16/weights/best.pt --data data/standard_train.yaml --img 620"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zelyeqbyt3GD"
      },
      "source": [
        "# Environments\n",
        "\n",
        "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):\n",
        "\n",
        "- **Notebooks** with free GPU: <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a> <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/google_cloud_quickstart_tutorial/)\n",
        "- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/aws_quickstart_tutorial/)\n",
        "- **Docker Image**. See [Docker Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/docker_image_quickstart_tutorial/) <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"Docker Pulls\"></a>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
